# 21点姿态估计模型 - 安装和推理使用说明

## 1 介绍

本项目基于 MMPose 框架，扩展了标准的 COCO 17点关键点模型，新增了4个脚部关键点（左右脚跟和左右脚尖），形成了**21点骨骼模型**。

### 关键点定义

| ID | 名称 | 类型 | 说明 |
|----|------|------|------|
| 0-16 | COCO标准17点 | - | 与COCO数据集一致 |
| 17 | left_heel | lower | 左脚跟 |
| 18 | right_heel | lower | 右脚跟 |
| 19 | left_foot | lower | 左脚尖 |
| 20 | right_foot | lower | 右脚尖 |

## 2 安装

已安装mmpose：

如果已经安装了mmpose，直接进行仓库克隆然后以可编辑的形式安装即可：

```bash
git clone https://github.com/liuxiaochao-satuo/mmpose_21keypoints_model.git
cd mmpose_21keypoints_model
pip install -v -e .
```
未安装mmpose：

如果未安装mmpose,请先参考mmpose官方文档进行MMEngine和MMCV安装 mmpose官方安装文档：https://mmpose.readthedocs.io/zh-cn/latest/installation.html

然后再克隆下载改动源码的mmpose,进行安装


#### 3 验证安装

```bash
python -c "from mmpose.datasets import CocoParallelDataset; print('✓ 21点模型安装成功')"
```


#### 4 放置权重文件

```bash
# 创建 checkpoints 目录
mkdir -p checkpoints

# 将权重文件放到 checkpoints 目录
# 例如：将 best_coco_AP_epoch_110.pth 复制到 checkpoints/ 目录
cp /path/to/downloaded/best_coco_AP_epoch_110.pth checkpoints/
```

## 5 推理使用

### 方法1：使用 Inferencer

#### 单张图片推理

```python
from mmpose.apis import MMPoseInferencer

# 创建推理器
# 注意：需要先创建配置文件，见下方"配置文件准备"
inferencer = MMPoseInferencer(
    pose2d='configs/body_2d_keypoint/dekr/coco/dekr_hrnet-w32_parallel.py',
    pose2d_weights='checkpoints/best_coco_AP_epoch_110.pth',
    device='cuda:0'  # 或 'cpu'
)

# 推理单张图片
result = inferencer('path/to/image.jpg', vis_out_dir='vis_results')
```

#### 视频推理

```python
from mmpose.apis import MMPoseInferencer

inferencer = MMPoseInferencer(
    pose2d='configs/body_2d_keypoint/dekr/coco/dekr_hrnet-w32_parallel.py',
    pose2d_weights='checkpoints/best_coco_AP_epoch_110.pth',
    device='cuda:0'
)

# 推理视频
result = inferencer('path/to/video.mp4', vis_out_dir='vis_results')
```

### 方法2：使用命令行工具

#### 单张图片

```bash
python demo/image_demo.py \
    path/to/image.jpg \
    configs/body_2d_keypoint/dekr/coco/dekr_hrnet-w32_parallel.py \
    checkpoints/best_coco_AP_epoch_110.pth \
    --out-file vis_results/result.jpg \
    --device cuda:0
```

#### 视频

```bash
python demo/image_demo.py \
    path/to/video.mp4 \
    configs/body_2d_keypoint/dekr/coco/dekr_hrnet-w32_parallel.py \
    checkpoints/best_coco_AP_epoch_110.pth \
    --out-file vis_results/result.mp4 \
    --device cuda:0
```

### 方法3：使用 Python API

```python
from mmpose.apis import inference_topdown, init_model
from mmpose.visualization import PoseLocalVisualizer
import cv2

# 初始化模型
model = init_model(
    config='configs/body_2d_keypoint/dekr/coco/dekr_hrnet-w32_parallel.py',
    checkpoint='checkpoints/best_coco_AP_epoch_110.pth',
    device='cuda:0'
)

# 读取图片
img = cv2.imread('path/to/image.jpg')

# 推理
results = inference_topdown(model, img)

# 可视化
visualizer = PoseLocalVisualizer()
vis_img = visualizer.add_datasample(
    'result',
    img,
    data_sample=results[0],
    draw_bbox=True,
    draw_heatmap=False,
    show_kpt_idx=False,
    skeleton_style='mmpose',
    show=False,
    wait_time=0,
    kpt_thr=0.3
)

# 保存结果
cv2.imwrite('vis_results/result.jpg', vis_img)
```

##  配置文件

配置文件已包含在项目中，位于：
- `configs/body_2d_keypoint/dekr/coco/dekr_hrnet-w32_parallel.py`

**无需手动创建配置文件，直接使用即可！**

