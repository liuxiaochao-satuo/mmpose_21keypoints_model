# 21点姿态估计模型 - 安装和推理使用说明

## 📖 简介

本项目基于 MMPose 框架，扩展了标准的 COCO 17点关键点模型，新增了4个脚部关键点（左右脚跟和左右脚尖），形成了**21点骨骼模型**。

### 关键点定义

| ID | 名称 | 类型 | 说明 |
|----|------|------|------|
| 0-16 | COCO标准17点 | - | 与COCO数据集一致 |
| 17 | left_heel | lower | 左脚跟 |
| 18 | right_heel | lower | 右脚跟 |
| 19 | left_foot | lower | 左脚尖 |
| 20 | right_foot | lower | 右脚尖 |

## 🚀 快速开始

### 步骤1：克隆仓库

```bash
git clone https://github.com/yourusername/mmpose-21keypoints.git
cd mmpose-21keypoints
```

### 步骤2：安装依赖

#### 2.1 环境要求

- Python >= 3.7
- PyTorch >= 1.8
- CUDA >= 10.2 (如使用GPU)

#### 2.2 安装步骤

```bash
# 1. 创建虚拟环境（推荐）
conda create -n mmpose python=3.8 -y
conda activate mmpose

# 或使用 venv
python -m venv venv
source venv/bin/activate  # Linux/Mac
# venv\Scripts\activate  # Windows

# 2. 安装 PyTorch（根据你的CUDA版本选择）
# CUDA 11.3
pip install torch==1.12.0+cu113 torchvision==0.13.0+cu113 -f https://download.pytorch.org/whl/torch_stable.html

# 或 CUDA 11.1
pip install torch==1.12.0+cu111 torchvision==0.13.0+cu111 -f https://download.pytorch.org/whl/torch_stable.html

# CPU版本
# pip install torch torchvision

# 3. 安装 mmcv-full
pip install mmcv-full -f https://download.openmmlab.com/mmcv/dist/cu113/torch1.12.0/index.html
# 注意：根据你的CUDA和PyTorch版本选择对应的mmcv-full版本
# 查看：https://mmcv.readthedocs.io/en/latest/get_started/installation.html

# 4. 安装其他依赖
pip install -r requirements.txt

# 5. 以开发模式安装 mmpose（包含21点模型）
pip install -e .
```

#### 2.3 验证安装

```bash
python -c "from mmpose.datasets import CocoParallelDataset; print('✓ 21点模型安装成功')"
```

### 步骤3：下载权重文件

#### 3.1 从网盘下载

1. **访问网盘链接**：[在此填入你的网盘链接]
2. **提取码**：[在此填入提取码]
3. **下载文件**：`best_coco_AP_epoch_110.pth` (约117MB)

#### 3.2 放置权重文件

```bash
# 创建 checkpoints 目录
mkdir -p checkpoints

# 将下载的权重文件放到 checkpoints 目录
# 例如：将 best_coco_AP_epoch_110.pth 复制到 checkpoints/ 目录
cp /path/to/downloaded/best_coco_AP_epoch_110.pth checkpoints/
```

**目录结构：**
```
mmpose-21keypoints/
├── checkpoints/
│   └── best_coco_AP_epoch_110.pth  # 权重文件
├── mmpose/
├── configs/
└── ...
```

## 💻 推理使用

### 方法1：使用 Inferencer（推荐，最简单）

#### 单张图片推理

```python
from mmpose.apis import MMPoseInferencer

# 创建推理器
# 注意：需要先创建配置文件，见下方"配置文件准备"
inferencer = MMPoseInferencer(
    pose2d='configs/body_2d_keypoint/dekr/coco/dekr_hrnet-w32_parallel.py',
    pose2d_weights='checkpoints/best_coco_AP_epoch_110.pth',
    device='cuda:0'  # 或 'cpu'
)

# 推理单张图片
result = inferencer('path/to/image.jpg', vis_out_dir='vis_results')
```

#### 视频推理

```python
from mmpose.apis import MMPoseInferencer

inferencer = MMPoseInferencer(
    pose2d='configs/body_2d_keypoint/dekr/coco/dekr_hrnet-w32_parallel.py',
    pose2d_weights='checkpoints/best_coco_AP_epoch_110.pth',
    device='cuda:0'
)

# 推理视频
result = inferencer('path/to/video.mp4', vis_out_dir='vis_results')
```

### 方法2：使用命令行工具

#### 单张图片

```bash
python demo/image_demo.py \
    path/to/image.jpg \
    configs/body_2d_keypoint/dekr/coco/dekr_hrnet-w32_parallel.py \
    checkpoints/best_coco_AP_epoch_110.pth \
    --out-file vis_results/result.jpg \
    --device cuda:0
```

#### 视频

```bash
python demo/image_demo.py \
    path/to/video.mp4 \
    configs/body_2d_keypoint/dekr/coco/dekr_hrnet-w32_parallel.py \
    checkpoints/best_coco_AP_epoch_110.pth \
    --out-file vis_results/result.mp4 \
    --device cuda:0
```

### 方法3：使用 Python API

```python
from mmpose.apis import inference_topdown, init_model
from mmpose.visualization import PoseLocalVisualizer
import cv2

# 初始化模型
model = init_model(
    config='configs/body_2d_keypoint/dekr/coco/dekr_hrnet-w32_parallel.py',
    checkpoint='checkpoints/best_coco_AP_epoch_110.pth',
    device='cuda:0'
)

# 读取图片
img = cv2.imread('path/to/image.jpg')

# 推理
results = inference_topdown(model, img)

# 可视化
visualizer = PoseLocalVisualizer()
vis_img = visualizer.add_datasample(
    'result',
    img,
    data_sample=results[0],
    draw_bbox=True,
    draw_heatmap=False,
    show_kpt_idx=False,
    skeleton_style='mmpose',
    show=False,
    wait_time=0,
    kpt_thr=0.3
)

# 保存结果
cv2.imwrite('vis_results/result.jpg', vis_img)
```

## 📝 配置文件

配置文件已包含在项目中，位于：
- `configs/body_2d_keypoint/dekr/coco/dekr_hrnet-w32_parallel.py`

**无需手动创建配置文件，直接使用即可！**

### 配置文件说明

配置文件已按照官方格式编写，包含：
- ✅ 21点模型配置（`num_keypoints=21`）
- ✅ 使用 `CocoParallelDataset` 数据集
- ✅ HRNet-W32 骨干网络
- ✅ DEKR 头部网络

### 如需自定义配置

如果需要修改配置，可以编辑 `configs/body_2d_keypoint/dekr/coco/dekr_hrnet-w32_parallel.py`。

**注意**：对于推理使用，数据集路径配置不是必需的，可以忽略训练相关的数据加载器配置。

### 配置文件模板（参考）

```python
# 配置文件位置：configs/body_2d_keypoint/dekr/coco/dekr_hrnet-w32_parallel.py
# 已包含完整的模型配置，包括：
# - 21点关键点模型（num_keypoints=21）
# - CocoParallelDataset 数据集
# - HRNet-W32 骨干网络
# - DEKR 头部网络

# 模型配置示例（实际配置已在文件中）：
model = dict(
    type='BottomupPoseEstimator',
    data_preprocessor=dict(
        type='PoseDataPreprocessor',
        mean=[123.675, 116.28, 103.53],
        std=[58.395, 57.12, 57.375],
        bgr_to_rgb=True),
    backbone=dict(
        type='HRNet',
        in_channels=3,
        extra=dict(
            stage1=dict(
                num_modules=1,
                num_branches=1,
                block='BOTTLENECK',
                num_blocks=(4, ),
                num_channels=(64, )),
            stage2=dict(
                num_modules=1,
                num_branches=2,
                block='BASIC',
                num_blocks=(4, 4),
                num_channels=(32, 64)),
            stage3=dict(
                num_modules=4,
                num_branches=3,
                block='BASIC',
                num_blocks=(4, 4, 4),
                num_channels=(32, 64, 128)),
            stage4=dict(
                num_modules=3,
                num_branches=4,
                block='BASIC',
                num_blocks=(4, 4, 4, 4),
                num_channels=(32, 64, 128, 256),
                multiscale_output=True)),
        init_cfg=dict(
            type='Pretrained',
            checkpoint='https://download.openmmlab.com/mmpose/pretrain_models/hrnet_w32-36af842e.pth'),
    ),
    neck=dict(
        type='FeatureMapProcessor',
        concat=True,
    ),
    head=dict(
        type='DEKRHead',
        in_channels=480,
        num_keypoints=21,  # 21个关键点
        num_heatmap_filters=480,
        num_offset_filters_per_joint=17,
        num_joints=21,  # 21个关键点
        heatmap_loss=dict(type='KeypointMSELoss', use_target_weight=True),
        offset_loss=dict(type='SoftWeightSmoothL1Loss', use_target_weight=True),
    ),
    test_cfg=dict(
        flip_test=True,
        shift_heatmap=True,
    ),
)
```

**或者**，如果你有完整的配置文件，可以直接使用。

## 🎯 完整推理示例

### 示例1：单张图片推理（完整代码）

创建文件 `inference_example.py`：

```python
#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""21点模型推理示例"""

from mmpose.apis import MMPoseInferencer
import argparse

def main():
    parser = argparse.ArgumentParser(description='21点模型推理')
    parser.add_argument('input', type=str, help='输入图片或视频路径')
    parser.add_argument('--config', type=str, 
                       default='configs/body_2d_keypoint/dekr/coco/dekr_hrnet-w32_parallel.py',
                       help='配置文件路径')
    parser.add_argument('--checkpoint', type=str,
                       default='checkpoints/best_coco_AP_epoch_110.pth',
                       help='权重文件路径')
    parser.add_argument('--output', type=str, default='vis_results',
                       help='输出目录')
    parser.add_argument('--device', type=str, default='cuda:0',
                       help='设备 (cuda:0 或 cpu)')
    
    args = parser.parse_args()
    
    # 创建推理器
    print(f"加载模型: {args.checkpoint}")
    inferencer = MMPoseInferencer(
        pose2d=args.config,
        pose2d_weights=args.checkpoint,
        device=args.device
    )
    
    # 推理
    print(f"推理: {args.input}")
    result = inferencer(args.input, vis_out_dir=args.output)
    
    print(f"结果已保存到: {args.output}")

if __name__ == '__main__':
    main()
```

**使用方法：**
```bash
python inference_example.py path/to/image.jpg
```

### 示例2：批量图片推理

```python
from mmpose.apis import MMPoseInferencer
from pathlib import Path

# 创建推理器
inferencer = MMPoseInferencer(
    pose2d='configs/body_2d_keypoint/dekr/coco/dekr_hrnet-w32_parallel.py',
    pose2d_weights='checkpoints/best_coco_AP_epoch_110.pth',
    device='cuda:0'
)

# 批量处理图片
image_dir = Path('path/to/images')
output_dir = Path('vis_results')

for img_path in image_dir.glob('*.jpg'):
    print(f"处理: {img_path}")
    inferencer(str(img_path), vis_out_dir=str(output_dir))
```

## 📊 获取关键点坐标

```python
from mmpose.apis import inference_topdown, init_model
import numpy as np

# 初始化模型
model = init_model(
    config='configs/body_2d_keypoint/dekr/coco/dekr_hrnet-w32_parallel.py',
    checkpoint='checkpoints/best_coco_AP_epoch_110.pth',
    device='cuda:0'
)

# 推理
img = 'path/to/image.jpg'
results = inference_topdown(model, img)

# 获取关键点坐标
for result in results:
    # 获取预测的关键点
    pred_instances = result.pred_instances
    
    # 关键点坐标 (N, 21, 2) - N个实例，21个关键点，每个点(x, y)
    keypoints = pred_instances.keypoints
    
    # 关键点置信度 (N, 21)
    keypoint_scores = pred_instances.keypoint_scores
    
    # 关键点名称（21个）
    keypoint_names = [
        'nose', 'left_eye', 'right_eye', 'left_ear', 'right_ear',
        'left_shoulder', 'right_shoulder', 'left_elbow', 'right_elbow',
        'left_wrist', 'right_wrist', 'left_hip', 'right_hip',
        'left_knee', 'right_knee', 'left_ankle', 'right_ankle',
        'left_heel', 'right_heel', 'left_foot', 'right_foot'
    ]
    
    # 打印第一个人的关键点
    if len(keypoints) > 0:
        person_kpts = keypoints[0]  # (21, 2)
        person_scores = keypoint_scores[0]  # (21,)
        
        for i, (name, kpt, score) in enumerate(zip(keypoint_names, person_kpts, person_scores)):
            if score > 0.3:  # 置信度阈值
                print(f"{i}: {name} - ({kpt[0]:.1f}, {kpt[1]:.1f}) - score: {score:.3f}")
```

## ⚙️ 常见问题

### Q1: 安装时出现 mmcv-full 错误

**A:** 根据你的 CUDA 和 PyTorch 版本安装对应的 mmcv-full：

```bash
# 查看支持的版本
# https://mmcv.readthedocs.io/en/latest/get_started/installation.html

# 例如：CUDA 11.3 + PyTorch 1.12.0
pip install mmcv-full -f https://download.openmmlab.com/mmcv/dist/cu113/torch1.12.0/index.html
```

### Q2: 推理时提示找不到配置文件

**A:** 确保配置文件路径正确，或者使用绝对路径：

```python
import os
config_path = os.path.abspath('configs/body_2d_keypoint/dekr/coco/dekr_hrnet-w32_parallel.py')
```

### Q3: CUDA out of memory

**A:** 
- 使用 CPU：`device='cpu'`
- 减小输入图片尺寸
- 使用更小的 batch size

### Q4: 如何只获取关键点坐标，不保存可视化图片？

**A:** 使用 `inference_topdown` API，不调用可视化函数。

## 📦 权重文件下载

### 网盘链接

- **下载链接**：[在此填入你的网盘链接]
- **提取码**：[在此填入提取码]
- **文件名**：`best_coco_AP_epoch_110.pth`
- **文件大小**：约 117MB

### 下载后验证

```bash
# 检查文件是否存在
ls -lh checkpoints/best_coco_AP_epoch_110.pth

# 应该显示约 117MB
```

## 🔗 相关资源

- [MMPose 官方文档](https://mmpose.readthedocs.io/)
- [MMPose GitHub](https://github.com/open-mmlab/mmpose)
- [21点模型改动说明](./21点模型改动说明.md)

## 📮 问题反馈

如有问题，请通过以下方式反馈：
- GitHub Issues: [在此填入你的仓库链接]
- 邮箱: [在此填入你的邮箱]

---

**祝使用愉快！** 🎉
